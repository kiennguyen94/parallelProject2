/*******************************************************************
  This file has been automatically generated by ispc
  DO NOT EDIT THIS FILE DIRECTLY
 *******************************************************************/

/* Provide Declarations */
#include <stdarg.h>
#include <setjmp.h>
#include <limits.h>
#include <stdlib.h>
#ifdef _MSC_VER
  #define NOMINMAX
  #include <windows.h>
#endif // _MSC_VER
#include <stdlib.h>
#include <stdint.h>
/* get a declaration for alloca */
#ifdef _MSC_VER
  #include <malloc.h>
  #define alloca _alloca
#else
  #include <alloca.h>
#endif

#undef ISPC_FAST_MATH
#include "generic_defs.h"

/* Basic Library Function Declarations */
extern "C" {
int puts(unsigned char *);
unsigned int putchar(unsigned int);
int fflush(void *);
int printf(const unsigned char *, ...);
uint8_t *memcpy(uint8_t *, uint8_t *, uint64_t );
uint8_t *memset(uint8_t *, uint8_t, uint64_t );
void memset_pattern16(void *, const void *, uint64_t );
}

#ifndef __GNUC__  /* Can only support "linkonce" vars with GCC */
#define __attribute__(X)
#endif

#if defined(__GNUC__) && defined(__APPLE_CC__)
#define __EXTERNAL_WEAK__ __attribute__((weak_import))
#elif defined(__GNUC__)
#define __EXTERNAL_WEAK__ __attribute__((weak))
#else
#define __EXTERNAL_WEAK__
#endif

#if defined(__GNUC__) && defined(__APPLE_CC__)
#define __ATTRIBUTE_WEAK__
#elif defined(__GNUC__)
#define __ATTRIBUTE_WEAK__ __attribute__((weak))
#else
#define __ATTRIBUTE_WEAK__
#endif

#if defined(__GNUC__)
#define __HIDDEN__ __attribute__((visibility("hidden")))
#endif

#if (defined(__GNUC__) || defined(__clang__)) && !defined(__INTEL_COMPILER)
#define LLVM_NAN(NanStr)   __builtin_nan(NanStr)   /* Double */
#define LLVM_NANF(NanStr)  __builtin_nanf(NanStr)  /* Float */
#define LLVM_NANS(NanStr)  __builtin_nans(NanStr)  /* Double */
#define LLVM_NANSF(NanStr) __builtin_nansf(NanStr) /* Float */
#define LLVM_INF           __builtin_inf()         /* Double */
#define LLVM_INFF          __builtin_inff()        /* Float */
//#define LLVM_PREFETCH(addr,rw,locality) __builtin_prefetch(addr,rw,locality)
//#define __ATTRIBUTE_CTOR__ __attribute__((constructor))
//#define __ATTRIBUTE_DTOR__ __attribute__((destructor))
#elif defined(_MSC_VER) || defined(__INTEL_COMPILER)
#include <limits>
#define LLVM_NAN(NanStr)   std::numeric_limits<double>::quiet_NaN()
#define LLVM_NANF(NanStr)  std::numeric_limits<float>::quiet_NaN()
#define LLVM_NANS(NanStr)  std::numeric_limits<double>::signaling_NaN()
#define LLVM_NANSF(NanStr) std::numeric_limits<float>::signaling_NaN()
#define LLVM_INF           std::numeric_limits<double>::infinity()
#define LLVM_INFF          std::numeric_limits<float>::infinity()
//#define LLVM_PREFETCH(addr,rw,locality)            /* PREFETCH */
//#define __ATTRIBUTE_CTOR__
//#define __ATTRIBUTE_DTOR__
#else
#error "Not MSVC, clang, or g++?"
#endif

#if (defined(__GNUC__) || defined(__clang__))
#define LLVM_ASM(X) __asm(X)
#endif

#if defined(__clang__) || defined(__INTEL_COMPILER) || (__GNUC__ < 4) /* Old GCCs, or compilers not GCC */ 
#define __builtin_stack_save() 0   /* not implemented */
#define __builtin_stack_restore(X) /* noop */
#endif

#define CODE_FOR_MAIN() /* Any target-specific code for main()*/

#ifndef __cplusplus
typedef unsigned char bool;
#endif


/* Support for floating point constants */
typedef uint64_t ConstantDoubleTy;
typedef uint32_t ConstantFloatTy;
typedef struct { unsigned long long f1; unsigned short f2; unsigned short pad[3]; } ConstantFP80Ty;
typedef struct { uint64_t f1, f2; } ConstantFP128Ty;


/* Global Declarations */


/* Helper union for bitcasts */
typedef union {
  unsigned int Int32;
  unsigned long long Int64;
  float Float;
  double Double;
} llvmBitCastUnion;

/* This is special class, designed for operations with long int.*/                       
namespace {                                                                                
template <int num_bits>                                                                    
struct iN {                                                                                
  int num[num_bits / (sizeof (int) * 8)];                                                  
                                                                                           
  iN () {}                                                                                 
                                                                                           
  iN (const char *val) {                                                                   
    if (val == NULL)                                                                       
      return;                                                                              
    int length = num_bits / (sizeof (int) * 8);                                            
    int val_len = 0;                                                                       
    for (val_len = 0; val[val_len]; (val_len)++);                                          
    for (int i = 0; (i < val_len && i < num_bits); i++)                                    
      num[i / (sizeof (int) * 8)] = (num[i / (sizeof (int) * 8)] << 1) | (val[i] - '0');   
  }                                                                                        
                                                                                           
  ~iN () {}                                                                                
                                                                                           
  iN operator >> (const iN rhs) {                                                          
    iN res;                                                                                
    int length = num_bits / (sizeof (int) * 8);                                            
    int cells_shift = rhs.num[0] / (sizeof(int) * 8);                                      
    int small_shift = rhs.num[0] % (sizeof(int) * 8);                                      
    for (int i = 0; i < (length - cells_shift); i++)                                       
      res.num[i] = this->num[cells_shift + i];                                             
    for (int i = 0; i < length - 1; i++) {                                                 
      res.num[i] = this->num[i] >> small_shift;                                            
      res.num[i]  = ((this->num[i + 1] << ((sizeof(int) * 8) - small_shift))) | res.num[i];
    }                                                                                      
    res.num[length - 1] = res.num[length - 1] >> small_shift;                              
    return res;                                                                            
  }                                                                                        
                                                                                           
  iN operator & (iN rhs) {                                                                 
    iN res;                                                                                
    int length = num_bits / (sizeof (int) * 8);                                            
    for (int i = 0; i < length; i++)                                                       
      res.num[i] = (this->num[i]) & (rhs.num[i]);                                          
    return res;                                                                            
  }                                                                                        
                                                                                           
  operator uint32_t() { return this->num[0]; }                                             
                                                                                           
  template <class T>                                                                       
  friend iN<num_bits> __cast_bits(iN<num_bits> to, T from) {                               
    for (int i = 0; i <4; i++)                                         
      to.num[i] = ((int*)(&from))[i];                                                      
    return to;                                                                             
  }                                                                                        
                                                                                           
  template <class T>                                                                       
  friend T __cast_bits(T to, iN<num_bits> from) {                                          
    for (int i = 0; i <4; i++)                                         
      ((int*)(&to))[i] = from.num[i];                                                      
    return to;                                                                             
  }                                                                                        
                                                                                           
  template <int ALIGN, class T>                                                            
  friend void __store(T *p, iN<num_bits> val) {                                            
    for (int i = 0; i <4; i++)                                         
      ((int*)p)[i] = val.num[i];                                                           
  }                                                                                        
};                                                                                         
};

/* Structure and array forward declarations */
struct l_unnamed_0;
namespace {
};

/* Structure and array contents */
struct l_unnamed_0 {
  static l_unnamed_0 init(uint32_t v0, float *v1, float *v2, uint32_t v3, __vec4_i1 v4) {
    l_unnamed_0 ret;
    ret.field0 = v0;
    ret.field1 = v1;
    ret.field2 = v2;
    ret.field3 = v3;
    ret.field4 = v4;
    return ret;
  }
  uint32_t field0;
  float *field1;
  float *field2;
  uint32_t field3;
  __vec4_i1 field4;
};

namespace {
};


/* Function Declarations */
extern "C" {
uint8_t *ISPCAlloc(uint8_t **, uint64_t , uint32_t );
void ISPCLaunch(uint8_t **, uint8_t *, uint8_t *, uint32_t , uint32_t , uint32_t );
void ISPCSync(uint8_t *);
void sqrt_ispc___uniun_3C_unf_3E_un_3C_unf_3E_(uint32_t N_, float *x_, float *out_, __vec4_i1 __mask_);
void do_sqrt___uniun_3C_unf_3E_un_3C_unf_3E_uni(l_unnamed_0 *, uint32_t , uint32_t , uint32_t , uint32_t , uint32_t , uint32_t , uint32_t , uint32_t , uint32_t , uint32_t );
void sqrt_ispc_task___uniun_3C_unf_3E_un_3C_unf_3E_uni(uint32_t N_, float *x_, float *out_, uint32_t num_tasks_, __vec4_i1 __mask_);
void sqrt_ispc(uint32_t N_, float *x_, float *out_);
void sqrt_ispc_task(uint32_t N_, float *x_, float *out_, uint32_t num_tasks_);
}



/* Function Bodies */
template <typename A, typename B> static inline int llvm_fcmp_ord(A X, B Y) { return X == X && Y == Y; }
template <typename A, typename B> static inline int llvm_fcmp_uno(A X, B Y) { return X != X || Y != Y; }
template <typename A, typename B> static inline int llvm_fcmp_ueq(A X, B Y) { return X == Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_une(A X, B Y) { return X != Y; }
template <typename A, typename B> static inline int llvm_fcmp_ult(A X, B Y) { return X <  Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_ugt(A X, B Y) { return X >  Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_ule(A X, B Y) { return X <= Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_uge(A X, B Y) { return X >= Y || llvm_fcmp_uno(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_oeq(A X, B Y) { return X == Y ; }
template <typename A, typename B> static inline int llvm_fcmp_one(A X, B Y) { return X != Y && llvm_fcmp_ord(X, Y); }
template <typename A, typename B> static inline int llvm_fcmp_olt(A X, B Y) { return X <  Y ; }
template <typename A, typename B> static inline int llvm_fcmp_ogt(A X, B Y) { return X >  Y ; }
template <typename A, typename B> static inline int llvm_fcmp_ole(A X, B Y) { return X <= Y ; }
template <typename A, typename B> static inline int llvm_fcmp_oge(A X, B Y) { return X >= Y ; }
template <typename A> A *Memset(A *ptr, int count, size_t len) { return (A *)memset(ptr, count, len); }

static const int32_t __attribute__ ((aligned(16))) VectorConstant0[] = { 0u, 1u, 2u, 3u,  };

void sqrt_ispc___uniun_3C_unf_3E_un_3C_unf_3E_(uint32_t N_, float *x_, float *out_, __vec4_i1 __mask_) {
  uint32_t aligned_end_;
  uint8_t *x_load_ptr2int_2void_;
  uint8_t *out_load_ptr2int_2void_;
  uint32_t counter_2e_1314_;
  uint32_t counter_2e_1314___PHI;
  uint64_t tmp__1_;
  __vec4_f ptr_masked_load249_;
  __vec4_i1 logical_or_;
  bool internal_mask_26_function_mask34_any_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec4_d div_n_load51__to_double_;
  __vec4_d n_load54_to_double_;
  __vec4_d sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_;
  __vec4_d sub_x_1_load_x_0_load57303_;
  __vec4_i1 logical_or61306_;
  bool internal_mask_26_function_mask67_any308_;
  __vec4_i1 oldMask_26_test63311_;
  __vec4_i1 oldMask_26_test63311___PHI;
  __vec4_d x_1_2e_0310_;
  __vec4_d x_1_2e_0310___PHI;
  __vec4_d x_0_2e_0309_;
  __vec4_d x_0_2e_0309___PHI;
  __vec4_d v1_2e_i_;
  __vec4_d v1_2e_i287_;
  __vec4_d sub_x_1_load_x_0_load57_;
  __vec4_i1 oldMask_26_test63_;
  bool internal_mask_26_function_mask67_any_;
  __vec4_d x_1_2e_0_2e_lcssa_;
  __vec4_d x_1_2e_0_2e_lcssa___PHI;
  uint32_t new_counter_;
  __vec4_i32 counter_2e_1_2e_lcssa_smear_;
  __vec4_i32 iter_val103_;
  __vec4_i32 N_smear_;
  __vec4_i1 cmp106_;
  uint64_t tmp__2_;
  __vec4_f ptr253_masked_load_;
  __vec4_i1 oldMask_26_test125_and_mask_;
  bool internal_mask_26_function_mask129_any_;
  __vec4_d div_n_load157__to_double_;
  __vec4_d n_load162_to_double_;
  __vec4_d sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_;
  __vec4_d sub_x_1_load171_x_0_load172294_;
  __vec4_i1 oldMask_26_test179298_and_mask_;
  bool internal_mask_26_function_mask183_any299_;
  __vec4_i1 oldMask_26_test179302_;
  __vec4_i1 oldMask_26_test179302___PHI;
  __vec4_d x_1158_2e_0301_;
  __vec4_d x_1158_2e_0301___PHI;
  __vec4_d x_0156_2e_0300_;
  __vec4_d x_0156_2e_0300___PHI;
  __vec4_d v1_2e_i285_;
  __vec4_d v1_2e_i283_;
  __vec4_d sub_x_1_load171_x_0_load172_;
  __vec4_i1 oldMask_26_test179_;
  bool internal_mask_26_function_mask183_any_;
  __vec4_d x_1158_2e_0_2e_lcssa_;
  __vec4_d x_1158_2e_0_2e_lcssa___PHI;

  aligned_end_ = ((uint32_t )(((uint32_t )N_) - ((uint32_t )(((int32_t )(((int32_t )N_) % ((int32_t )4u)))))));
  if ((((int32_t )aligned_end_) > ((int32_t )0u))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = 0u;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  x_load_ptr2int_2void_ = ((uint8_t *)x_);
  out_load_ptr2int_2void_ = ((uint8_t *)out_);
  counter_2e_1314___PHI = 0u;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1314_ = counter_2e_1314___PHI;
  tmp__1_ = ((int64_t )(int32_t )(counter_2e_1314_ << 2u));
  ptr_masked_load249_ = __load<4>((((__vec4_f (*))((&x_load_ptr2int_2void_[((int64_t )tmp__1_)])))));
  logical_or_ = __or((__equal_float(ptr_masked_load249_, __setzero_float<__vec4_f>())), (__equal_float(ptr_masked_load249_, __smear_float<__vec4_f>(0x1p+0))));
  internal_mask_26_function_mask34_any_ = (( /*tail*/ __any(logical_or_))&1);
  if (internal_mask_26_function_mask34_any_) {
    goto safe_if_run_true_label;
  } else {
    goto safe_if_after_true_label;
  }

}
safe_if_run_true_label: {
  __masked_store_float((((__vec4_f (*))((&out_load_ptr2int_2void_[((int64_t )tmp__1_)])))), ptr_masked_load249_, logical_or_);
  goto safe_if_after_true_label;

}
safe_if_after_true_label: {
  div_n_load51__to_double_ = (__cast_fpext(__vec4_d (), (__div(ptr_masked_load249_, __smear_float<__vec4_f>(0x1p+2)))));
  n_load54_to_double_ = (__cast_fpext(__vec4_d (), ptr_masked_load249_));
  sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_ = __sub(div_n_load51__to_double_, (__div((__sub((__mul(div_n_load51__to_double_, div_n_load51__to_double_)), n_load54_to_double_)), (__mul(div_n_load51__to_double_, __smear_double<__vec4_d>(0x1p+1))))));
  sub_x_1_load_x_0_load57303_ = __sub(sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_, div_n_load51__to_double_);
  logical_or61306_ = __or((__greater_than_double(sub_x_1_load_x_0_load57303_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load_x_0_load57303_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))));
  internal_mask_26_function_mask67_any308_ = (( /*tail*/ __any(logical_or61306_))&1);
  if (internal_mask_26_function_mask67_any308_) {
    oldMask_26_test63311___PHI = logical_or61306_;   /* for PHI node */
    x_1_2e_0310___PHI = sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_;   /* for PHI node */
    x_0_2e_0309___PHI = div_n_load51__to_double_;   /* for PHI node */
    goto for_loop_label;
  } else {
    x_1_2e_0_2e_lcssa___PHI = sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_;   /* for PHI node */
    goto for_exit_label;
  }

}
  do {     /* Syntactic loop 'for_loop' to make GCC happy */
for_loop_label: {
  oldMask_26_test63311_ = oldMask_26_test63311___PHI;
  x_1_2e_0310_ = x_1_2e_0310___PHI;
  x_0_2e_0309_ = x_0_2e_0309___PHI;
  v1_2e_i_ = __select(oldMask_26_test63311_, x_1_2e_0310_, x_0_2e_0309_);
  v1_2e_i287_ = __select(oldMask_26_test63311_, (__sub(v1_2e_i_, (__div((__sub((__mul(v1_2e_i_, v1_2e_i_)), n_load54_to_double_)), (__mul(v1_2e_i_, __smear_double<__vec4_d>(0x1p+1))))))), x_1_2e_0310_);
  sub_x_1_load_x_0_load57_ = __sub(v1_2e_i287_, v1_2e_i_);
  oldMask_26_test63_ = __and((__or((__greater_than_double(sub_x_1_load_x_0_load57_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load_x_0_load57_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))), oldMask_26_test63311_);
  internal_mask_26_function_mask67_any_ = (( /*tail*/ __any(oldMask_26_test63_))&1);
  if (internal_mask_26_function_mask67_any_) {
    oldMask_26_test63311___PHI = oldMask_26_test63_;   /* for PHI node */
    x_1_2e_0310___PHI = v1_2e_i287_;   /* for PHI node */
    x_0_2e_0309___PHI = v1_2e_i_;   /* for PHI node */
    goto for_loop_label;
  } else {
    x_1_2e_0_2e_lcssa___PHI = v1_2e_i287_;   /* for PHI node */
    goto for_exit_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop' */
for_exit_label: {
  x_1_2e_0_2e_lcssa_ = x_1_2e_0_2e_lcssa___PHI;
  __store<4>((((__vec4_f (*))((&out_load_ptr2int_2void_[((int64_t )tmp__1_)])))), ((__cast_fptrunc(__vec4_f (), x_1_2e_0_2e_lcssa_))));
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1314_) + ((uint32_t )4u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1314___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )N_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec4_i32>(counter_2e_1_2e_lcssa_);
  iter_val103_ = __add(counter_2e_1_2e_lcssa_smear_, __load<16>((const __vec4_i32  *)(VectorConstant0)));
  N_smear_ = __smear_i32<__vec4_i32>(N_);
  cmp106_ = __signed_less_than_i32(iter_val103_, N_smear_);
  tmp__2_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr253_masked_load_ =  /*tail*/ __masked_load_float(((&(((uint8_t *)x_))[((int64_t )tmp__2_)])), cmp106_);
  oldMask_26_test125_and_mask_ = __signed_less_than_i32_and_mask(iter_val103_, N_smear_, (__or((__equal_float(ptr253_masked_load_, __setzero_float<__vec4_f>())), (__equal_float(ptr253_masked_load_, __smear_float<__vec4_f>(0x1p+0))))));
  internal_mask_26_function_mask129_any_ = (( /*tail*/ __any(oldMask_26_test125_and_mask_))&1);
  if (internal_mask_26_function_mask129_any_) {
    goto safe_if_run_true124_label;
  } else {
    goto safe_if_after_true123_label;
  }

}
safe_if_after_true123_label: {
  div_n_load157__to_double_ = (__cast_fpext(__vec4_d (), (__div(ptr253_masked_load_, __smear_float<__vec4_f>(0x1p+2)))));
  n_load162_to_double_ = (__cast_fpext(__vec4_d (), ptr253_masked_load_));
  sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_ = __sub(div_n_load157__to_double_, (__div((__sub((__mul(div_n_load157__to_double_, div_n_load157__to_double_)), n_load162_to_double_)), (__mul(div_n_load157__to_double_, __smear_double<__vec4_d>(0x1p+1))))));
  sub_x_1_load171_x_0_load172294_ = __sub(sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_, div_n_load157__to_double_);
  oldMask_26_test179298_and_mask_ = __signed_less_than_i32_and_mask(iter_val103_, N_smear_, (__or((__greater_than_double(sub_x_1_load171_x_0_load172294_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load171_x_0_load172294_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))));
  internal_mask_26_function_mask183_any299_ = (( /*tail*/ __any(oldMask_26_test179298_and_mask_))&1);
  if (internal_mask_26_function_mask183_any299_) {
    oldMask_26_test179302___PHI = oldMask_26_test179298_and_mask_;   /* for PHI node */
    x_1158_2e_0301___PHI = sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_;   /* for PHI node */
    x_0156_2e_0300___PHI = div_n_load157__to_double_;   /* for PHI node */
    goto for_loop166_label;
  } else {
    x_1158_2e_0_2e_lcssa___PHI = sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_;   /* for PHI node */
    goto for_exit167_label;
  }

}
safe_if_run_true124_label: {
  __masked_store_float((((__vec4_f (*))((&(((uint8_t *)out_))[((int64_t )tmp__2_)])))), ptr253_masked_load_, oldMask_26_test125_and_mask_);
  goto safe_if_after_true123_label;

}
  do {     /* Syntactic loop 'for_loop166' to make GCC happy */
for_loop166_label: {
  oldMask_26_test179302_ = oldMask_26_test179302___PHI;
  x_1158_2e_0301_ = x_1158_2e_0301___PHI;
  x_0156_2e_0300_ = x_0156_2e_0300___PHI;
  v1_2e_i285_ = __select(oldMask_26_test179302_, x_1158_2e_0301_, x_0156_2e_0300_);
  v1_2e_i283_ = __select(oldMask_26_test179302_, (__sub(v1_2e_i285_, (__div((__sub((__mul(v1_2e_i285_, v1_2e_i285_)), n_load162_to_double_)), (__mul(v1_2e_i285_, __smear_double<__vec4_d>(0x1p+1))))))), x_1158_2e_0301_);
  sub_x_1_load171_x_0_load172_ = __sub(v1_2e_i283_, v1_2e_i285_);
  oldMask_26_test179_ = __and((__or((__greater_than_double(sub_x_1_load171_x_0_load172_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load171_x_0_load172_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))), oldMask_26_test179302_);
  internal_mask_26_function_mask183_any_ = (( /*tail*/ __any(oldMask_26_test179_))&1);
  if (internal_mask_26_function_mask183_any_) {
    oldMask_26_test179302___PHI = oldMask_26_test179_;   /* for PHI node */
    x_1158_2e_0301___PHI = v1_2e_i283_;   /* for PHI node */
    x_0156_2e_0300___PHI = v1_2e_i285_;   /* for PHI node */
    goto for_loop166_label;
  } else {
    x_1158_2e_0_2e_lcssa___PHI = v1_2e_i283_;   /* for PHI node */
    goto for_exit167_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop166' */
for_exit167_label: {
  x_1158_2e_0_2e_lcssa_ = x_1158_2e_0_2e_lcssa___PHI;
  __masked_store_float((((__vec4_f (*))((&(((uint8_t *)out_))[((int64_t )tmp__2_)])))), ((__cast_fptrunc(__vec4_f (), x_1158_2e_0_2e_lcssa_))), cmp106_);
  goto foreach_reset_label;

}
}


static const int32_t __attribute__ ((aligned(16))) VectorConstant1[] = { 0u, 1u, 2u, 3u,  };

void do_sqrt___uniun_3C_unf_3E_un_3C_unf_3E_uni(l_unnamed_0 *tmp__3_, uint32_t tmp__4_, uint32_t tmp__5_, uint32_t tmp__6_, uint32_t tmp__7_, uint32_t tmp__8_, uint32_t tmp__9_, uint32_t tmp__10_, uint32_t tmp__11_, uint32_t tmp__12_, uint32_t tmp__13_) {
  uint32_t N2_;
  float *x4_;
  float *out6_;
  uint32_t space8_;
  uint32_t mul_taskIndex_load_space_load_;
  uint32_t calltmp_2e_i_;
  uint32_t aligned_end_;
  uint8_t *x_load_ptr2int_2void_;
  uint8_t *out_load_ptr2int_2void_;
  uint32_t counter_2e_1325_;
  uint32_t counter_2e_1325___PHI;
  uint64_t tmp__14_;
  __vec4_f ptr_masked_load260_;
  __vec4_i1 logical_or_;
  bool internal_mask_26_function_mask43_any_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec4_d div_n_load60__to_double_;
  __vec4_d n_load63_to_double_;
  __vec4_d sub_x_0_load_div_sub_mul_x_0_load61_x_0_load62_n_load63_to_double_mul__x_0_load64_;
  __vec4_d sub_x_1_load_x_0_load66314_;
  __vec4_i1 logical_or70317_;
  bool internal_mask_26_function_mask76_any319_;
  __vec4_i1 oldMask_26_test72322_;
  __vec4_i1 oldMask_26_test72322___PHI;
  __vec4_d x_1_2e_0321_;
  __vec4_d x_1_2e_0321___PHI;
  __vec4_d x_0_2e_0320_;
  __vec4_d x_0_2e_0320___PHI;
  __vec4_d v1_2e_i_;
  __vec4_d v1_2e_i298_;
  __vec4_d sub_x_1_load_x_0_load66_;
  __vec4_i1 oldMask_26_test72_;
  bool internal_mask_26_function_mask76_any_;
  __vec4_d x_1_2e_0_2e_lcssa_;
  __vec4_d x_1_2e_0_2e_lcssa___PHI;
  uint32_t new_counter_;
  __vec4_i32 counter_2e_1_2e_lcssa_smear_;
  __vec4_i32 iter_val112_;
  __vec4_i32 calltmp_2e_i_smear_;
  __vec4_i1 cmp115_;
  uint64_t tmp__15_;
  __vec4_f ptr264_masked_load_;
  __vec4_i1 oldMask_26_test134_and_mask_;
  bool internal_mask_26_function_mask138_any_;
  __vec4_d div_n_load166__to_double_;
  __vec4_d n_load171_to_double_;
  __vec4_d sub_x_0_load168_div_sub_mul_x_0_load169_x_0_load170_n_load171_to_double_mul__x_0_load172_;
  __vec4_d sub_x_1_load180_x_0_load181305_;
  __vec4_i1 oldMask_26_test188309_and_mask_;
  bool internal_mask_26_function_mask192_any310_;
  __vec4_i1 oldMask_26_test188313_;
  __vec4_i1 oldMask_26_test188313___PHI;
  __vec4_d x_1167_2e_0312_;
  __vec4_d x_1167_2e_0312___PHI;
  __vec4_d x_0165_2e_0311_;
  __vec4_d x_0165_2e_0311___PHI;
  __vec4_d v1_2e_i296_;
  __vec4_d v1_2e_i294_;
  __vec4_d sub_x_1_load180_x_0_load181_;
  __vec4_i1 oldMask_26_test188_;
  bool internal_mask_26_function_mask192_any_;
  __vec4_d x_1167_2e_0_2e_lcssa_;
  __vec4_d x_1167_2e_0_2e_lcssa___PHI;

  N2_ = *((&tmp__3_->field0));
  x4_ = *((&tmp__3_->field1));
  out6_ = *((&tmp__3_->field2));
  space8_ = *((&tmp__3_->field3));
  mul_taskIndex_load_space_load_ = ((uint32_t )(((uint32_t )space8_) * ((uint32_t )tmp__6_)));
  calltmp_2e_i_ =  /*tail*/ __min_uniform_uint32((((uint32_t )(((uint32_t )space8_) * ((uint32_t )(((uint32_t )(((uint32_t )tmp__6_) + ((uint32_t )1u)))))))), N2_);
  aligned_end_ = ((uint32_t )(((uint32_t )calltmp_2e_i_) - ((uint32_t )(((int32_t )(((int32_t )(((uint32_t )(((uint32_t )calltmp_2e_i_) - ((uint32_t )mul_taskIndex_load_space_load_))))) % ((int32_t )4u)))))));
  if ((((int32_t )mul_taskIndex_load_space_load_) < ((int32_t )aligned_end_))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = mul_taskIndex_load_space_load_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  x_load_ptr2int_2void_ = ((uint8_t *)x4_);
  out_load_ptr2int_2void_ = ((uint8_t *)out6_);
  counter_2e_1325___PHI = mul_taskIndex_load_space_load_;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1325_ = counter_2e_1325___PHI;
  tmp__14_ = ((int64_t )(int32_t )(counter_2e_1325_ << 2u));
  ptr_masked_load260_ = __load<4>((((__vec4_f (*))((&x_load_ptr2int_2void_[((int64_t )tmp__14_)])))));
  logical_or_ = __or((__equal_float(ptr_masked_load260_, __setzero_float<__vec4_f>())), (__equal_float(ptr_masked_load260_, __smear_float<__vec4_f>(0x1p+0))));
  internal_mask_26_function_mask43_any_ = (( /*tail*/ __any(logical_or_))&1);
  if (internal_mask_26_function_mask43_any_) {
    goto safe_if_run_true_label;
  } else {
    goto safe_if_after_true_label;
  }

}
safe_if_run_true_label: {
  __masked_store_float((((__vec4_f (*))((&out_load_ptr2int_2void_[((int64_t )tmp__14_)])))), ptr_masked_load260_, logical_or_);
  goto safe_if_after_true_label;

}
safe_if_after_true_label: {
  div_n_load60__to_double_ = (__cast_fpext(__vec4_d (), (__div(ptr_masked_load260_, __smear_float<__vec4_f>(0x1p+2)))));
  n_load63_to_double_ = (__cast_fpext(__vec4_d (), ptr_masked_load260_));
  sub_x_0_load_div_sub_mul_x_0_load61_x_0_load62_n_load63_to_double_mul__x_0_load64_ = __sub(div_n_load60__to_double_, (__div((__sub((__mul(div_n_load60__to_double_, div_n_load60__to_double_)), n_load63_to_double_)), (__mul(div_n_load60__to_double_, __smear_double<__vec4_d>(0x1p+1))))));
  sub_x_1_load_x_0_load66314_ = __sub(sub_x_0_load_div_sub_mul_x_0_load61_x_0_load62_n_load63_to_double_mul__x_0_load64_, div_n_load60__to_double_);
  logical_or70317_ = __or((__greater_than_double(sub_x_1_load_x_0_load66314_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load_x_0_load66314_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))));
  internal_mask_26_function_mask76_any319_ = (( /*tail*/ __any(logical_or70317_))&1);
  if (internal_mask_26_function_mask76_any319_) {
    oldMask_26_test72322___PHI = logical_or70317_;   /* for PHI node */
    x_1_2e_0321___PHI = sub_x_0_load_div_sub_mul_x_0_load61_x_0_load62_n_load63_to_double_mul__x_0_load64_;   /* for PHI node */
    x_0_2e_0320___PHI = div_n_load60__to_double_;   /* for PHI node */
    goto for_loop_label;
  } else {
    x_1_2e_0_2e_lcssa___PHI = sub_x_0_load_div_sub_mul_x_0_load61_x_0_load62_n_load63_to_double_mul__x_0_load64_;   /* for PHI node */
    goto for_exit_label;
  }

}
  do {     /* Syntactic loop 'for_loop' to make GCC happy */
for_loop_label: {
  oldMask_26_test72322_ = oldMask_26_test72322___PHI;
  x_1_2e_0321_ = x_1_2e_0321___PHI;
  x_0_2e_0320_ = x_0_2e_0320___PHI;
  v1_2e_i_ = __select(oldMask_26_test72322_, x_1_2e_0321_, x_0_2e_0320_);
  v1_2e_i298_ = __select(oldMask_26_test72322_, (__sub(v1_2e_i_, (__div((__sub((__mul(v1_2e_i_, v1_2e_i_)), n_load63_to_double_)), (__mul(v1_2e_i_, __smear_double<__vec4_d>(0x1p+1))))))), x_1_2e_0321_);
  sub_x_1_load_x_0_load66_ = __sub(v1_2e_i298_, v1_2e_i_);
  oldMask_26_test72_ = __and((__or((__greater_than_double(sub_x_1_load_x_0_load66_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load_x_0_load66_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))), oldMask_26_test72322_);
  internal_mask_26_function_mask76_any_ = (( /*tail*/ __any(oldMask_26_test72_))&1);
  if (internal_mask_26_function_mask76_any_) {
    oldMask_26_test72322___PHI = oldMask_26_test72_;   /* for PHI node */
    x_1_2e_0321___PHI = v1_2e_i298_;   /* for PHI node */
    x_0_2e_0320___PHI = v1_2e_i_;   /* for PHI node */
    goto for_loop_label;
  } else {
    x_1_2e_0_2e_lcssa___PHI = v1_2e_i298_;   /* for PHI node */
    goto for_exit_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop' */
for_exit_label: {
  x_1_2e_0_2e_lcssa_ = x_1_2e_0_2e_lcssa___PHI;
  __store<4>((((__vec4_f (*))((&out_load_ptr2int_2void_[((int64_t )tmp__14_)])))), ((__cast_fptrunc(__vec4_f (), x_1_2e_0_2e_lcssa_))));
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1325_) + ((uint32_t )4u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1325___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )calltmp_2e_i_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec4_i32>(counter_2e_1_2e_lcssa_);
  iter_val112_ = __add(counter_2e_1_2e_lcssa_smear_, __load<16>((const __vec4_i32  *)(VectorConstant1)));
  calltmp_2e_i_smear_ = __smear_i32<__vec4_i32>(calltmp_2e_i_);
  cmp115_ = __signed_less_than_i32(iter_val112_, calltmp_2e_i_smear_);
  tmp__15_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr264_masked_load_ =  /*tail*/ __masked_load_float(((&(((uint8_t *)x4_))[((int64_t )tmp__15_)])), cmp115_);
  oldMask_26_test134_and_mask_ = __signed_less_than_i32_and_mask(iter_val112_, calltmp_2e_i_smear_, (__or((__equal_float(ptr264_masked_load_, __setzero_float<__vec4_f>())), (__equal_float(ptr264_masked_load_, __smear_float<__vec4_f>(0x1p+0))))));
  internal_mask_26_function_mask138_any_ = (( /*tail*/ __any(oldMask_26_test134_and_mask_))&1);
  if (internal_mask_26_function_mask138_any_) {
    goto safe_if_run_true133_label;
  } else {
    goto safe_if_after_true132_label;
  }

}
safe_if_after_true132_label: {
  div_n_load166__to_double_ = (__cast_fpext(__vec4_d (), (__div(ptr264_masked_load_, __smear_float<__vec4_f>(0x1p+2)))));
  n_load171_to_double_ = (__cast_fpext(__vec4_d (), ptr264_masked_load_));
  sub_x_0_load168_div_sub_mul_x_0_load169_x_0_load170_n_load171_to_double_mul__x_0_load172_ = __sub(div_n_load166__to_double_, (__div((__sub((__mul(div_n_load166__to_double_, div_n_load166__to_double_)), n_load171_to_double_)), (__mul(div_n_load166__to_double_, __smear_double<__vec4_d>(0x1p+1))))));
  sub_x_1_load180_x_0_load181305_ = __sub(sub_x_0_load168_div_sub_mul_x_0_load169_x_0_load170_n_load171_to_double_mul__x_0_load172_, div_n_load166__to_double_);
  oldMask_26_test188309_and_mask_ = __signed_less_than_i32_and_mask(iter_val112_, calltmp_2e_i_smear_, (__or((__greater_than_double(sub_x_1_load180_x_0_load181305_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load180_x_0_load181305_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))));
  internal_mask_26_function_mask192_any310_ = (( /*tail*/ __any(oldMask_26_test188309_and_mask_))&1);
  if (internal_mask_26_function_mask192_any310_) {
    oldMask_26_test188313___PHI = oldMask_26_test188309_and_mask_;   /* for PHI node */
    x_1167_2e_0312___PHI = sub_x_0_load168_div_sub_mul_x_0_load169_x_0_load170_n_load171_to_double_mul__x_0_load172_;   /* for PHI node */
    x_0165_2e_0311___PHI = div_n_load166__to_double_;   /* for PHI node */
    goto for_loop175_label;
  } else {
    x_1167_2e_0_2e_lcssa___PHI = sub_x_0_load168_div_sub_mul_x_0_load169_x_0_load170_n_load171_to_double_mul__x_0_load172_;   /* for PHI node */
    goto for_exit176_label;
  }

}
safe_if_run_true133_label: {
  __masked_store_float((((__vec4_f (*))((&(((uint8_t *)out6_))[((int64_t )tmp__15_)])))), ptr264_masked_load_, oldMask_26_test134_and_mask_);
  goto safe_if_after_true132_label;

}
  do {     /* Syntactic loop 'for_loop175' to make GCC happy */
for_loop175_label: {
  oldMask_26_test188313_ = oldMask_26_test188313___PHI;
  x_1167_2e_0312_ = x_1167_2e_0312___PHI;
  x_0165_2e_0311_ = x_0165_2e_0311___PHI;
  v1_2e_i296_ = __select(oldMask_26_test188313_, x_1167_2e_0312_, x_0165_2e_0311_);
  v1_2e_i294_ = __select(oldMask_26_test188313_, (__sub(v1_2e_i296_, (__div((__sub((__mul(v1_2e_i296_, v1_2e_i296_)), n_load171_to_double_)), (__mul(v1_2e_i296_, __smear_double<__vec4_d>(0x1p+1))))))), x_1167_2e_0312_);
  sub_x_1_load180_x_0_load181_ = __sub(v1_2e_i294_, v1_2e_i296_);
  oldMask_26_test188_ = __and((__or((__greater_than_double(sub_x_1_load180_x_0_load181_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load180_x_0_load181_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))), oldMask_26_test188313_);
  internal_mask_26_function_mask192_any_ = (( /*tail*/ __any(oldMask_26_test188_))&1);
  if (internal_mask_26_function_mask192_any_) {
    oldMask_26_test188313___PHI = oldMask_26_test188_;   /* for PHI node */
    x_1167_2e_0312___PHI = v1_2e_i294_;   /* for PHI node */
    x_0165_2e_0311___PHI = v1_2e_i296_;   /* for PHI node */
    goto for_loop175_label;
  } else {
    x_1167_2e_0_2e_lcssa___PHI = v1_2e_i294_;   /* for PHI node */
    goto for_exit176_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop175' */
for_exit176_label: {
  x_1167_2e_0_2e_lcssa_ = x_1167_2e_0_2e_lcssa___PHI;
  __masked_store_float((((__vec4_f (*))((&(((uint8_t *)out6_))[((int64_t )tmp__15_)])))), ((__cast_fptrunc(__vec4_f (), x_1167_2e_0_2e_lcssa_))), cmp115_);
  goto foreach_reset_label;

}
}



void sqrt_ispc_task___uniun_3C_unf_3E_un_3C_unf_3E_uni(uint32_t N_, float *x_, float *out_, uint32_t num_tasks_, __vec4_i1 __mask_) {
  uint8_t *launch_group_handle_;    /* Address-exposed local */
  uint8_t *args_ptr_;
  uint32_t *tmp__16_;
  uint8_t *launch_group_handle_load_;

  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  args_ptr_ = ISPCAlloc((&launch_group_handle_), 48ull, 16u);
  *(((uint32_t *)args_ptr_)) = N_;
  *(((float **)((&args_ptr_[((int64_t )8ull)])))) = x_;
  *(((float **)((&args_ptr_[((int64_t )16ull)])))) = out_;
  tmp__16_ = ((uint32_t *)((&args_ptr_[((int64_t )24ull)])));
  if ((((int32_t )N_) > ((int32_t )num_tasks_))) {
    goto if_else_label;
  } else {
    goto if_then_label;
  }

if_then_label: {
  *tmp__16_ = num_tasks_;
  __store<16>((((__vec4_i1 (*))((&args_ptr_[((int64_t )32ull)])))), __mask_);
  ISPCLaunch((&launch_group_handle_), ((uint8_t *)do_sqrt___uniun_3C_unf_3E_un_3C_unf_3E_uni), args_ptr_, 1u, 1u, 1u);
  goto if_exit_label;

}
if_else_label: {
  *tmp__16_ = (((uint32_t )(((uint32_t )(((int32_t )(((int32_t )N_) / ((int32_t )num_tasks_))))) + ((uint32_t )1u))));
  __store<16>((((__vec4_i1 (*))((&args_ptr_[((int64_t )32ull)])))), __mask_);
  ISPCLaunch((&launch_group_handle_), ((uint8_t *)do_sqrt___uniun_3C_unf_3E_un_3C_unf_3E_uni), args_ptr_, num_tasks_, 1u, 1u);
  goto if_exit_label;

}
if_exit_label: {
  launch_group_handle_load_ = *(&launch_group_handle_);
  if ((launch_group_handle_load_ == ((uint8_t *)/*NULL*/0))) {
    goto post_sync_label;
  } else {
    goto call_sync_label;
  }

}
call_sync_label: {
  ISPCSync(launch_group_handle_load_);
  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  goto post_sync_label;

}
post_sync_label: {
  return;
}
}


static const int32_t __attribute__ ((aligned(16))) VectorConstant2[] = { 0u, 1u, 2u, 3u,  };

void sqrt_ispc(uint32_t N_, float *x_, float *out_) {
  uint32_t aligned_end_;
  uint8_t *x_load_ptr2int_2void_;
  uint8_t *out_load_ptr2int_2void_;
  uint32_t counter_2e_1314_;
  uint32_t counter_2e_1314___PHI;
  uint64_t tmp__17_;
  __vec4_f ptr_masked_load249_;
  __vec4_i1 logical_or_;
  bool internal_mask_26_function_mask34_any_;
  uint32_t counter_2e_1_2e_lcssa_;
  uint32_t counter_2e_1_2e_lcssa___PHI;
  __vec4_d div_n_load51__to_double_;
  __vec4_d n_load54_to_double_;
  __vec4_d sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_;
  __vec4_d sub_x_1_load_x_0_load57303_;
  __vec4_i1 logical_or61306_;
  bool internal_mask_26_function_mask67_any308_;
  __vec4_i1 oldMask_26_test63311_;
  __vec4_i1 oldMask_26_test63311___PHI;
  __vec4_d x_1_2e_0310_;
  __vec4_d x_1_2e_0310___PHI;
  __vec4_d x_0_2e_0309_;
  __vec4_d x_0_2e_0309___PHI;
  __vec4_d v1_2e_i_;
  __vec4_d v1_2e_i287_;
  __vec4_d sub_x_1_load_x_0_load57_;
  __vec4_i1 oldMask_26_test63_;
  bool internal_mask_26_function_mask67_any_;
  __vec4_d x_1_2e_0_2e_lcssa_;
  __vec4_d x_1_2e_0_2e_lcssa___PHI;
  uint32_t new_counter_;
  __vec4_i32 counter_2e_1_2e_lcssa_smear_;
  __vec4_i32 iter_val103_;
  __vec4_i32 N_smear_;
  __vec4_i1 cmp106_;
  uint64_t tmp__18_;
  __vec4_f ptr253_masked_load_;
  __vec4_i1 oldMask_26_test125_and_mask_;
  bool internal_mask_26_function_mask129_any_;
  __vec4_d div_n_load157__to_double_;
  __vec4_d n_load162_to_double_;
  __vec4_d sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_;
  __vec4_d sub_x_1_load171_x_0_load172294_;
  __vec4_i1 oldMask_26_test179298_and_mask_;
  bool internal_mask_26_function_mask183_any299_;
  __vec4_i1 oldMask_26_test179302_;
  __vec4_i1 oldMask_26_test179302___PHI;
  __vec4_d x_1158_2e_0301_;
  __vec4_d x_1158_2e_0301___PHI;
  __vec4_d x_0156_2e_0300_;
  __vec4_d x_0156_2e_0300___PHI;
  __vec4_d v1_2e_i285_;
  __vec4_d v1_2e_i283_;
  __vec4_d sub_x_1_load171_x_0_load172_;
  __vec4_i1 oldMask_26_test179_;
  bool internal_mask_26_function_mask183_any_;
  __vec4_d x_1158_2e_0_2e_lcssa_;
  __vec4_d x_1158_2e_0_2e_lcssa___PHI;

  aligned_end_ = ((uint32_t )(((uint32_t )N_) - ((uint32_t )(((int32_t )(((int32_t )N_) % ((int32_t )4u)))))));
  if ((((int32_t )aligned_end_) > ((int32_t )0u))) {
    goto foreach_full_body_2e_lr_2e_ph_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = 0u;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

foreach_full_body_2e_lr_2e_ph_label: {
  x_load_ptr2int_2void_ = ((uint8_t *)x_);
  out_load_ptr2int_2void_ = ((uint8_t *)out_);
  counter_2e_1314___PHI = 0u;   /* for PHI node */
  goto foreach_full_body_label;

}
  do {     /* Syntactic loop 'foreach_full_body' to make GCC happy */
foreach_full_body_label: {
  counter_2e_1314_ = counter_2e_1314___PHI;
  tmp__17_ = ((int64_t )(int32_t )(counter_2e_1314_ << 2u));
  ptr_masked_load249_ = __load<4>((((__vec4_f (*))((&x_load_ptr2int_2void_[((int64_t )tmp__17_)])))));
  logical_or_ = __or((__equal_float(ptr_masked_load249_, __setzero_float<__vec4_f>())), (__equal_float(ptr_masked_load249_, __smear_float<__vec4_f>(0x1p+0))));
  internal_mask_26_function_mask34_any_ = (( /*tail*/ __any(logical_or_))&1);
  if (internal_mask_26_function_mask34_any_) {
    goto safe_if_run_true_label;
  } else {
    goto safe_if_after_true_label;
  }

}
safe_if_run_true_label: {
  __masked_store_float((((__vec4_f (*))((&out_load_ptr2int_2void_[((int64_t )tmp__17_)])))), ptr_masked_load249_, logical_or_);
  goto safe_if_after_true_label;

}
safe_if_after_true_label: {
  div_n_load51__to_double_ = (__cast_fpext(__vec4_d (), (__div(ptr_masked_load249_, __smear_float<__vec4_f>(0x1p+2)))));
  n_load54_to_double_ = (__cast_fpext(__vec4_d (), ptr_masked_load249_));
  sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_ = __sub(div_n_load51__to_double_, (__div((__sub((__mul(div_n_load51__to_double_, div_n_load51__to_double_)), n_load54_to_double_)), (__mul(div_n_load51__to_double_, __smear_double<__vec4_d>(0x1p+1))))));
  sub_x_1_load_x_0_load57303_ = __sub(sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_, div_n_load51__to_double_);
  logical_or61306_ = __or((__greater_than_double(sub_x_1_load_x_0_load57303_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load_x_0_load57303_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))));
  internal_mask_26_function_mask67_any308_ = (( /*tail*/ __any(logical_or61306_))&1);
  if (internal_mask_26_function_mask67_any308_) {
    oldMask_26_test63311___PHI = logical_or61306_;   /* for PHI node */
    x_1_2e_0310___PHI = sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_;   /* for PHI node */
    x_0_2e_0309___PHI = div_n_load51__to_double_;   /* for PHI node */
    goto for_loop_label;
  } else {
    x_1_2e_0_2e_lcssa___PHI = sub_x_0_load_div_sub_mul_x_0_load52_x_0_load53_n_load54_to_double_mul__x_0_load55_;   /* for PHI node */
    goto for_exit_label;
  }

}
  do {     /* Syntactic loop 'for_loop' to make GCC happy */
for_loop_label: {
  oldMask_26_test63311_ = oldMask_26_test63311___PHI;
  x_1_2e_0310_ = x_1_2e_0310___PHI;
  x_0_2e_0309_ = x_0_2e_0309___PHI;
  v1_2e_i_ = __select(oldMask_26_test63311_, x_1_2e_0310_, x_0_2e_0309_);
  v1_2e_i287_ = __select(oldMask_26_test63311_, (__sub(v1_2e_i_, (__div((__sub((__mul(v1_2e_i_, v1_2e_i_)), n_load54_to_double_)), (__mul(v1_2e_i_, __smear_double<__vec4_d>(0x1p+1))))))), x_1_2e_0310_);
  sub_x_1_load_x_0_load57_ = __sub(v1_2e_i287_, v1_2e_i_);
  oldMask_26_test63_ = __and((__or((__greater_than_double(sub_x_1_load_x_0_load57_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load_x_0_load57_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))), oldMask_26_test63311_);
  internal_mask_26_function_mask67_any_ = (( /*tail*/ __any(oldMask_26_test63_))&1);
  if (internal_mask_26_function_mask67_any_) {
    oldMask_26_test63311___PHI = oldMask_26_test63_;   /* for PHI node */
    x_1_2e_0310___PHI = v1_2e_i287_;   /* for PHI node */
    x_0_2e_0309___PHI = v1_2e_i_;   /* for PHI node */
    goto for_loop_label;
  } else {
    x_1_2e_0_2e_lcssa___PHI = v1_2e_i287_;   /* for PHI node */
    goto for_exit_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop' */
for_exit_label: {
  x_1_2e_0_2e_lcssa_ = x_1_2e_0_2e_lcssa___PHI;
  __store<4>((((__vec4_f (*))((&out_load_ptr2int_2void_[((int64_t )tmp__17_)])))), ((__cast_fptrunc(__vec4_f (), x_1_2e_0_2e_lcssa_))));
  new_counter_ = ((uint32_t )(((uint32_t )counter_2e_1314_) + ((uint32_t )4u)));
  if ((((int32_t )new_counter_) < ((int32_t )aligned_end_))) {
    counter_2e_1314___PHI = new_counter_;   /* for PHI node */
    goto foreach_full_body_label;
  } else {
    counter_2e_1_2e_lcssa___PHI = new_counter_;   /* for PHI node */
    goto partial_inner_all_outer_label;
  }

}
  } while (1); /* end of syntactic loop 'foreach_full_body' */
foreach_reset_label: {
  return;
}
partial_inner_all_outer_label: {
  counter_2e_1_2e_lcssa_ = counter_2e_1_2e_lcssa___PHI;
  if ((((int32_t )counter_2e_1_2e_lcssa_) < ((int32_t )N_))) {
    goto partial_inner_only_label;
  } else {
    goto foreach_reset_label;
  }

}
partial_inner_only_label: {
  counter_2e_1_2e_lcssa_smear_ = __smear_i32<__vec4_i32>(counter_2e_1_2e_lcssa_);
  iter_val103_ = __add(counter_2e_1_2e_lcssa_smear_, __load<16>((const __vec4_i32  *)(VectorConstant2)));
  N_smear_ = __smear_i32<__vec4_i32>(N_);
  cmp106_ = __signed_less_than_i32(iter_val103_, N_smear_);
  tmp__18_ = ((int64_t )(int32_t )(counter_2e_1_2e_lcssa_ << 2u));
  ptr253_masked_load_ =  /*tail*/ __masked_load_float(((&(((uint8_t *)x_))[((int64_t )tmp__18_)])), cmp106_);
  oldMask_26_test125_and_mask_ = __signed_less_than_i32_and_mask(iter_val103_, N_smear_, (__or((__equal_float(ptr253_masked_load_, __setzero_float<__vec4_f>())), (__equal_float(ptr253_masked_load_, __smear_float<__vec4_f>(0x1p+0))))));
  internal_mask_26_function_mask129_any_ = (( /*tail*/ __any(oldMask_26_test125_and_mask_))&1);
  if (internal_mask_26_function_mask129_any_) {
    goto safe_if_run_true124_label;
  } else {
    goto safe_if_after_true123_label;
  }

}
safe_if_after_true123_label: {
  div_n_load157__to_double_ = (__cast_fpext(__vec4_d (), (__div(ptr253_masked_load_, __smear_float<__vec4_f>(0x1p+2)))));
  n_load162_to_double_ = (__cast_fpext(__vec4_d (), ptr253_masked_load_));
  sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_ = __sub(div_n_load157__to_double_, (__div((__sub((__mul(div_n_load157__to_double_, div_n_load157__to_double_)), n_load162_to_double_)), (__mul(div_n_load157__to_double_, __smear_double<__vec4_d>(0x1p+1))))));
  sub_x_1_load171_x_0_load172294_ = __sub(sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_, div_n_load157__to_double_);
  oldMask_26_test179298_and_mask_ = __signed_less_than_i32_and_mask(iter_val103_, N_smear_, (__or((__greater_than_double(sub_x_1_load171_x_0_load172294_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load171_x_0_load172294_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))));
  internal_mask_26_function_mask183_any299_ = (( /*tail*/ __any(oldMask_26_test179298_and_mask_))&1);
  if (internal_mask_26_function_mask183_any299_) {
    oldMask_26_test179302___PHI = oldMask_26_test179298_and_mask_;   /* for PHI node */
    x_1158_2e_0301___PHI = sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_;   /* for PHI node */
    x_0156_2e_0300___PHI = div_n_load157__to_double_;   /* for PHI node */
    goto for_loop166_label;
  } else {
    x_1158_2e_0_2e_lcssa___PHI = sub_x_0_load159_div_sub_mul_x_0_load160_x_0_load161_n_load162_to_double_mul__x_0_load163_;   /* for PHI node */
    goto for_exit167_label;
  }

}
safe_if_run_true124_label: {
  __masked_store_float((((__vec4_f (*))((&(((uint8_t *)out_))[((int64_t )tmp__18_)])))), ptr253_masked_load_, oldMask_26_test125_and_mask_);
  goto safe_if_after_true123_label;

}
  do {     /* Syntactic loop 'for_loop166' to make GCC happy */
for_loop166_label: {
  oldMask_26_test179302_ = oldMask_26_test179302___PHI;
  x_1158_2e_0301_ = x_1158_2e_0301___PHI;
  x_0156_2e_0300_ = x_0156_2e_0300___PHI;
  v1_2e_i285_ = __select(oldMask_26_test179302_, x_1158_2e_0301_, x_0156_2e_0300_);
  v1_2e_i283_ = __select(oldMask_26_test179302_, (__sub(v1_2e_i285_, (__div((__sub((__mul(v1_2e_i285_, v1_2e_i285_)), n_load162_to_double_)), (__mul(v1_2e_i285_, __smear_double<__vec4_d>(0x1p+1))))))), x_1158_2e_0301_);
  sub_x_1_load171_x_0_load172_ = __sub(v1_2e_i283_, v1_2e_i285_);
  oldMask_26_test179_ = __and((__or((__greater_than_double(sub_x_1_load171_x_0_load172_, __smear_double<__vec4_d>(0x1.a36e2ep-14))), (__less_than_double(sub_x_1_load171_x_0_load172_, __smear_double<__vec4_d>(-0x1.a36e2ep-14))))), oldMask_26_test179302_);
  internal_mask_26_function_mask183_any_ = (( /*tail*/ __any(oldMask_26_test179_))&1);
  if (internal_mask_26_function_mask183_any_) {
    oldMask_26_test179302___PHI = oldMask_26_test179_;   /* for PHI node */
    x_1158_2e_0301___PHI = v1_2e_i283_;   /* for PHI node */
    x_0156_2e_0300___PHI = v1_2e_i285_;   /* for PHI node */
    goto for_loop166_label;
  } else {
    x_1158_2e_0_2e_lcssa___PHI = v1_2e_i283_;   /* for PHI node */
    goto for_exit167_label;
  }

}
  } while (1); /* end of syntactic loop 'for_loop166' */
for_exit167_label: {
  x_1158_2e_0_2e_lcssa_ = x_1158_2e_0_2e_lcssa___PHI;
  __masked_store_float((((__vec4_f (*))((&(((uint8_t *)out_))[((int64_t )tmp__18_)])))), ((__cast_fptrunc(__vec4_f (), x_1158_2e_0_2e_lcssa_))), cmp106_);
  goto foreach_reset_label;

}
}



void sqrt_ispc_task(uint32_t N_, float *x_, float *out_, uint32_t num_tasks_) {
  uint8_t *launch_group_handle_;    /* Address-exposed local */
  uint8_t *args_ptr_;
  uint32_t *tmp__19_;
  uint8_t *launch_group_handle_load_;

  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  args_ptr_ = ISPCAlloc((&launch_group_handle_), 48ull, 16u);
  *(((uint32_t *)args_ptr_)) = N_;
  *(((float **)((&args_ptr_[((int64_t )8ull)])))) = x_;
  *(((float **)((&args_ptr_[((int64_t )16ull)])))) = out_;
  tmp__19_ = ((uint32_t *)((&args_ptr_[((int64_t )24ull)])));
  if ((((int32_t )N_) > ((int32_t )num_tasks_))) {
    goto if_else_label;
  } else {
    goto if_then_label;
  }

if_then_label: {
  *tmp__19_ = num_tasks_;
  __store<16>((((__vec4_i1 (*))((&args_ptr_[((int64_t )32ull)])))), __smear_i1<__vec4_i1>(1));
  ISPCLaunch((&launch_group_handle_), ((uint8_t *)do_sqrt___uniun_3C_unf_3E_un_3C_unf_3E_uni), args_ptr_, 1u, 1u, 1u);
  goto if_exit_label;

}
if_else_label: {
  *tmp__19_ = (((uint32_t )(((uint32_t )(((int32_t )(((int32_t )N_) / ((int32_t )num_tasks_))))) + ((uint32_t )1u))));
  __store<16>((((__vec4_i1 (*))((&args_ptr_[((int64_t )32ull)])))), __smear_i1<__vec4_i1>(1));
  ISPCLaunch((&launch_group_handle_), ((uint8_t *)do_sqrt___uniun_3C_unf_3E_un_3C_unf_3E_uni), args_ptr_, num_tasks_, 1u, 1u);
  goto if_exit_label;

}
if_exit_label: {
  launch_group_handle_load_ = *(&launch_group_handle_);
  if ((launch_group_handle_load_ == ((uint8_t *)/*NULL*/0))) {
    goto post_sync_label;
  } else {
    goto call_sync_label;
  }

}
call_sync_label: {
  ISPCSync(launch_group_handle_load_);
  *(&launch_group_handle_) = ((uint8_t *)/*NULL*/0);
  goto post_sync_label;

}
post_sync_label: {
  return;
}
}

